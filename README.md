
# SPECTER REVIEW
This project presents an overview of the paper
titled ”SPECTER: Document-level Representation Learning using
Citation-informed Transformers”. The paper introduces
SPECTER, a novel approach for document-level representation
learning that leverages citation information to enhance the
performance of transformer-based models. The report provides
a summary of the key contributions, methodology, experimental
results, and implications of the proposed SPECTER model.
As an extension, We tried to improve SPECTER classification
performance on the MeSH and MAG tasks by mounting a MLP
classification head on top of SPECTER.

To run the experiments, follow the SPECTER_project notebook using Google colab.

Trained models can be downloaded from the following link: [the Google Drive link provided before](https://drive.google.com/drive/folders/14NAz5m6pOUlWq-kf5nGq7LWWSEhJzqOs?usp=share_link).

Data is available at the following link:  ([this one](https://drive.google.com/drive/folders/1Tlh55ElWXjtDc5Dsgm8qLhh9BEtEn4sw?usp=share_link) for the data).
